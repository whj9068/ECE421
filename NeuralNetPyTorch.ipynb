{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCaJD8A354cJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "40fbcc9f-9a98-41c2-c5cc-47e74dec932f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Accuracy: 87.61 | Validation Accuracy: 84.77 | Test Accuracy: 85.98\n",
            "Epoch: 1 | Train Accuracy: 92.20 | Validation Accuracy: 87.65 | Test Accuracy: 88.51\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-910c863a0517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m \u001b[0mcompare_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;31m#Experiment 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-910c863a0517>\u001b[0m in \u001b[0;36mcompare_arch\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;31m#Experiment 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompare_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m   \u001b[0mCNNmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNNacc_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done CNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0mFNNmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFNNacc_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-910c863a0517>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(model_type, learning_rate, dropout_rate, weight_decay, num_epochs, verbose)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m   \u001b[0;31m# Release the model from the GPU (else the memory wont hold up)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-910c863a0517>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, learning_rate, weight_decay, train_loader, val_loader, test_loader, num_epochs, verbose)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0macc_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0macc_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0macc_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-910c863a0517>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "'''\n",
        "Inputs: datafile\n",
        "The default input is ”\"notMNIST.npz\", which is the dataset we are using in this assignment.\n",
        "\n",
        "Output: trainData, validData, testData, trainTarget, validTarget, testTarget\n",
        "The outputs are images and annotations in the form of Numpy matrices. trainData and trainTarget are the images and annotations for training. Similarly, validData and validTarget are the images and annotations for validation and testData and testTarget are the images and annotations for testing.\n",
        "'''\n",
        "# Function for loading notMNIST Dataset\n",
        "def loadData(datafile = \"notMNIST.npz\"):\n",
        "    with np.load(datafile) as data:\n",
        "        Data, Target = data[\"images\"].astype(np.float32), data[\"labels\"]\n",
        "        np.random.seed(521)\n",
        "        randIndx = np.arange(len(Data))\n",
        "        np.random.shuffle(randIndx)\n",
        "        Data = Data[randIndx] / 255.0\n",
        "        Target = Target[randIndx]\n",
        "        trainData, trainTarget = Data[:10000], Target[:10000]\n",
        "        validData, validTarget = Data[10000:16000], Target[10000:16000]\n",
        "        testData, testTarget = Data[16000:], Target[16000:]\n",
        "    return trainData, validData, testData, trainTarget, validTarget, testTarget\n",
        "\n",
        "# Custom Dataset class.\n",
        "class notMNIST(Dataset):\n",
        "    def __init__(self, annotations, images, transform=None, target_transform=None):\n",
        "        self.img_labels = annotations\n",
        "        self.imgs = images\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.imgs[idx]\n",
        "        label = self.img_labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "#Define CNN\n",
        "class CNN(nn.Module):\n",
        "    '''\n",
        "    Inputs: self, drop out p\n",
        "    The input drop out p is a scalar that represents the dropout rate of the dropout layer in the neural network.\n",
        "    '''\n",
        "    def __init__(self, drop_out_p=0.0):\n",
        "        #TODO\n",
        "        #DEFINE YOUR LAYERS HERE\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=4)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "        self.pooling1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.dropout = nn.Dropout(p=drop_out_p)\n",
        "        self.linear1 = nn.Linear(1024,784)\n",
        "        self.linear2 = nn.Linear(784,10)\n",
        "\n",
        "    '''\n",
        "    Inputs: self, x\n",
        "    The input x is the batch of images of size (BATCH SIZE, 1, 28, 28). The input self represents the instance of the class.\n",
        "\n",
        "    Output: out\n",
        "    This function computes the logits for each image in the batch. The output has a size of(BATCH SIZE, 10), where each (i,j) position represent the class-logit score j of image i.\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "        #TODO\n",
        "        #DEFINE YOUR FORWARD FUNCTION HERE\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.batchnorm1(x)\n",
        "\n",
        "        x = self.pooling1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.batchnorm2(x)\n",
        "\n",
        "        x = self.pooling2(x)\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        output = self.linear2(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "#Define FNN\n",
        "class FNN(nn.Module):\n",
        "    '''\n",
        "    Inputs: self, drop out p\n",
        "    The input drop out p is a scalar that represents the dropout rate of the dropout layer in the neural network. The input self represents the instance of the class.\n",
        "    '''\n",
        "    def __init__(self, drop_out_p=0.0):\n",
        "        super(FNN, self).__init__()\n",
        "        #TODO\n",
        "        #DEFINE YOUR LAYERS HERE\n",
        "        self.linear1 = nn.Linear(784, 10)\n",
        "        self.linear2 = nn.Linear(10, 10)\n",
        "        self.linear3 = nn.Linear(10, 10)\n",
        "        self.dropout = nn.Dropout(p=drop_out_p)\n",
        "\n",
        "    '''\n",
        "    Inputs: self, x\n",
        "    The input x is the batch of images of size (BATCH SIZE, 1, 28, 28). We use self input represents the instance of the class.\n",
        "\n",
        "    Output: out\n",
        "    This function computes the logits for each image in the batch. The output has a size of (BATCH SIZE, 10), where each (i,j) position represent the class-logit score j of image i belongs to class j.\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "        #TODO\n",
        "        #DEFINE YOUR FORWARD FUNCTION HERE\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.linear2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        output = self.linear3(x)\n",
        "        return output\n",
        "\n",
        "'''\n",
        "Inputs: model, dataloader\n",
        "model is an instance of the neural network class. dataloader is an instance of the notMNIST dataloader (see the function experiment).\n",
        "\n",
        "Output:\n",
        "The output of this function is a scalar, which is the accuracy over all images in dataloader.\n",
        "'''\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Compute accuracy\n",
        "def get_accuracy(model, dataloader):\n",
        "\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # TODO\n",
        "            # Return the accuracy\n",
        "            # Enable GPU usage\n",
        "            image = images.cuda()\n",
        "            label = labels.cuda()\n",
        "            prediction = torch.argmax(model(image), dim=1)\n",
        "            accuracy += (prediction == label).sum().item()\n",
        "            total += len(image)\n",
        "    return (100 * accuracy/total)\n",
        "'''\n",
        "Inputs: model, device, learning rate, weight decay, train loader, val loader, test loader, num epochs=50, verbose\n",
        "model is an instance of the neural network class. To train the neural networks with GPU, device should be \"cuda:0\" as shown in the experiment function. The learning rate,\n",
        "weight decay and float scalars that specify the learning rate and L2 weight decay of the model.\n",
        "train loader, val loader, test loader are the notMNIST dataloader for training, validation and testing set respectively. num epochs is the number of passes through the dataset\n",
        "we would like in our training (default is 50 in this assignment). Finally, set verbose to True will print out the training progress.\n",
        "\n",
        "Output: model, acc hist\n",
        "This function will return a trained model and the evolution of training, validation and testing accuracy\n",
        "'''\n",
        "def train(model, device, learning_rate, weight_decay, train_loader, val_loader, test_loader, num_epochs=50, verbose=False):\n",
        "  #TODO\n",
        "  # Define your cross entropy loss function here\n",
        "  # Use cross entropy loss\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  #TODO\n",
        "  # Define your optimizer here\n",
        "  # Use AdamW optimizer, set the weights, learning rate and weight decay argument.\n",
        "  optimizer = torch.optim.AdamW(model.parameters(),weight_decay = weight_decay, lr=learning_rate)\n",
        "\n",
        "  acc_hist = {'train':[], 'val':[], 'test': []}\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model = model.train()\n",
        "    ## training step\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # TODO\n",
        "        # Follow the step in the tutorial\n",
        "        ## forward + backprop + loss\n",
        "\n",
        "        # Enable GPU usage\n",
        "\n",
        "        image = images.cuda()\n",
        "        label = labels.cuda()\n",
        "\n",
        "\n",
        "\n",
        "        logits = model(image)\n",
        "        loss = criterion(logits, label)\n",
        "        ## update model params\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    acc_hist['train'].append(get_accuracy(model, train_loader))\n",
        "    acc_hist['val'].append(get_accuracy(model, val_loader))\n",
        "    acc_hist['test'].append(get_accuracy(model, test_loader))\n",
        "\n",
        "    if verbose:\n",
        "      print('Epoch: %d | Train Accuracy: %.2f | Validation Accuracy: %.2f | Test Accuracy: %.2f' \\\n",
        "           %(epoch, acc_hist['train'][-1], acc_hist['val'][-1], acc_hist['test'][-1]))\n",
        "\n",
        "  return model, acc_hist\n",
        "\n",
        "def experiment(model_type='CNN', learning_rate=0.0001, dropout_rate=0.5, weight_decay=0.01, num_epochs=50, verbose=False):\n",
        "  # Use GPU if it is available.\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  # Inpute Batch size:\n",
        "  BATCH_SIZE = 32\n",
        "\n",
        "  # Convert images to tensor\n",
        "  transform = transforms.Compose(\n",
        "      [transforms.ToTensor()])\n",
        "\n",
        "  # Get train, validation and test data loader.\n",
        "  trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
        "\n",
        "  train_data = notMNIST(trainTarget, trainData, transform=transform)\n",
        "  val_data = notMNIST(validTarget, validData, transform=transform)\n",
        "  test_data = notMNIST(testTarget, testData, transform=transform)\n",
        "\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  val_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "  # Specify which model to use\n",
        "  if model_type == 'CNN':\n",
        "    model = CNN(dropout_rate)\n",
        "  elif model_type == 'FNN':\n",
        "    model = FNN(dropout_rate)\n",
        "\n",
        "\n",
        "  # Loading model into device\n",
        "  model = model.to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  model, acc_hist = train(model, device, learning_rate, weight_decay, train_loader, val_loader, test_loader, num_epochs=num_epochs, verbose=verbose)\n",
        "\n",
        "  # Release the model from the GPU (else the memory wont hold up)\n",
        "  model.cpu()\n",
        "\n",
        "  return model, acc_hist\n",
        "\n",
        "#Experiment 1\n",
        "def compare_arch(num_epochs=50):\n",
        "  CNNmodel, CNNacc_hist = experiment(model_type = 'CNN', dropout_rate = 0.0, weight_decay = 0.0,verbose = True)\n",
        "  print(\"done CNN\")\n",
        "  FNNmodel, FNNacc_hist = experiment(model_type = 'FNN', dropout_rate = 0.0, weight_decay = 0.0, verbose = True)\n",
        "  epochs = np.arange(0,num_epochs,1)\n",
        "  plt.title(\"Traning Accuracy for CNN and FNN\")\n",
        "  plt.plot(epochs,CNNacc_hist['train'],markeredgecolor='r',label='CNN')\n",
        "  plt.plot(epochs,FNNacc_hist['train'],markeredgecolor='G',label='FNN')\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Training Accuracy in %\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.title(\"Testing Accuracy for CNN and FNN\")\n",
        "  plt.plot(epochs,CNNacc_hist['test'],markeredgecolor='r',label='CNN')\n",
        "  plt.plot(epochs,FNNacc_hist['test'],markeredgecolor='G',label='FNN')\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Testing Accuracy in %\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "compare_arch()\n",
        "\n",
        "#Experiment 2\n",
        "def compare_dropout(num_epochs=50):\n",
        "  model1, acc_hist1 = experiment(model_type = 'CNN', dropout_rate = 0.5, weight_decay = 0.0,verbose = True)\n",
        "  model2, acc_hist2 = experiment(model_type = 'CNN', dropout_rate = 0.8, weight_decay = 0.0,verbose = True)\n",
        "  model3, acc_hist3 = experiment(model_type = 'CNN', dropout_rate = 0.95, weight_decay = 0.0,verbose = True)\n",
        "  epochs = np.arange(0,num_epochs,1)\n",
        "  plt.title(\"Traning Accuracy for three different CNN dropout rates\")\n",
        "  plt.plot(epochs,acc_hist1['train'],label='DR=0.5',markeredgecolor='r')\n",
        "  plt.plot(epochs,acc_hist2['train'],label='DR=0.8',markeredgecolor='g')\n",
        "  plt.plot(epochs,acc_hist3['train'],label='DR=0.95',markeredgecolor='b')\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Training Accuracy in %\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.title(\"Testing Accuracy for three different CNN dropout rates\")\n",
        "  plt.plot(epochs,acc_hist1['test'],label='DR=0.5',markeredgecolor='r')\n",
        "  plt.plot(epochs,acc_hist2['test'],label='DR=0.8',markeredgecolor='g')\n",
        "  plt.plot(epochs,acc_hist3['test'],label='DR=0.95',markeredgecolor='b')\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Testing Accuracy in %\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "compare_dropout()\n",
        "\n",
        "#Experiment 3\n",
        "def compare_l2(num_epochs=50):\n",
        "  model1, acc_hist1 = experiment(model_type = 'CNN', dropout_rate = 0.0, weight_decay = 0.1,verbose = True)\n",
        "  model2, acc_hist2 = experiment(model_type = 'CNN', dropout_rate = 0.0, weight_decay = 1.0,verbose = True)\n",
        "  model3, acc_hist3 = experiment(model_type = 'CNN', dropout_rate = 0.0, weight_decay = 10.0,verbose = True)\n",
        "  epochs = np.arange(0,num_epochs,1)\n",
        "  plt.title(\"Traning Accuracy for three different CNN weight decays\")\n",
        "  plt.plot(epochs,acc_hist1['train'],label='WD=0.1',markeredgecolor='r')\n",
        "  plt.plot(epochs,acc_hist2['train'],label='WD=1.0',markeredgecolor='g')\n",
        "  plt.plot(epochs,acc_hist3['train'],label='WD=10.0',markeredgecolor='b')\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Training Accuracy in %\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.title(\"Testing Accuracy for three different CNN weight decays\")\n",
        "  plt.plot(epochs,acc_hist1['test'],label='WD=0.1',markeredgecolor='r')\n",
        "  plt.plot(epochs,acc_hist2['test'],label='WD=1.0',markeredgecolor='g')\n",
        "  plt.plot(epochs,acc_hist3['test'],label='WD=10.0',markeredgecolor='b')\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Testing Accuracy in %\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "compare_l2()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "SDJwVjzj2g7J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mzv01kWySALK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
