{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGmmofoPvkQH",
        "outputId": "c8a96495-f90b-4edc-fd32-cd05b670f6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------Test Result-------------------\n",
            "Confusion Matrix is from Part 1a is:  [[ 8  0]\n",
            " [ 0 12]]\n",
            "Confusion Matrix from Part 1b is: [[ 7  1]\n",
            " [ 0 12]]\n"
          ]
        }
      ],
      "source": [
        "#import library\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#This function will output the optimal w after updating 5000 times\n",
        "def fit_perceptron(X_train, y_train):\n",
        "  #add a column of 1 before x_i\n",
        "  X_i = np.hstack((np.ones((len(X_train),1)),X_train))\n",
        "  #initialize w as matrix of 0\n",
        "  w = np.zeros((5001,len(X_i[0])))\n",
        "  #calculate the first Ein\n",
        "  E_in_best = errorPer(X_train,y_train,w[0])\n",
        "  #initialize w_best as 0\n",
        "  w_best = np.zeros(len(X_i[0]))\n",
        "  count = 0\n",
        "  #stop when Ein equals 0\n",
        "  while (E_in_best > 0 and count < 5000-1):\n",
        "    for j in range(len(X_i)):\n",
        "      y_pred = pred(X_i[j],w[count])\n",
        "      if y_pred != y_train[j]:\n",
        "        #w[t+1] = w[t]+ YX\n",
        "        w[count + 1] = w[count] + np.dot(y_train[j],X_i[j])\n",
        "        #calculate new error for new w\n",
        "        E_in_current = errorPer(X_train, y_train, w[count+1])\n",
        "        if E_in_current < E_in_best:\n",
        "          #update new error for new w\n",
        "          E_in_best = E_in_current\n",
        "          w_best = w[count+1]\n",
        "        if (count < (5000 - 1)and E_in_best > 0):\n",
        "          count += 1\n",
        "        else:\n",
        "          break\n",
        "  return w_best\n",
        "\n",
        "#This function calculate Ein with given w\n",
        "def errorPer(X_train,y_train,w):\n",
        "  #confusion matrix\n",
        "  error = 0\n",
        "  count = confMatrix(X_train,y_train,w)\n",
        "  error += count[1][0]\n",
        "  error += count[0][1]\n",
        "  error /= len(X_train)\n",
        "  return error\n",
        "\n",
        "#This function output a confusion matrix with given w. Inside the matrix, [0][0] count true negatives, [1][0] count false negatives, [0][1] count false positive, and [1][1] count true positive\n",
        "def confMatrix(X_train,y_train,w):\n",
        "  #confusion matrix\n",
        "  X_i = np.hstack((np.ones((len(X_train),1)),X_train))\n",
        "  count = np.zeros((2,2),dtype=np.int16)\n",
        "  for i in range(len(X_i)):\n",
        "    if(y_train[i]==1):\n",
        "      if pred(X_i[i],w) != y_train[i]:\n",
        "        count[1][0]+=1\n",
        "      else:\n",
        "        count[1][1]+=1\n",
        "    else:\n",
        "      if pred(X_i[i],w) != y_train[i]:\n",
        "        count[0][1]+=1\n",
        "      else:\n",
        "        count[0][0]+=1\n",
        "  return count\n",
        "\n",
        "#This function output prediction of y with given w\n",
        "def pred(X_train,w):\n",
        "  #calculate predicted y value\n",
        "  value = np.dot(X_train,w)\n",
        "  if (value>0):\n",
        "    return 1\n",
        "  else:\n",
        "    return -1\n",
        "\n",
        "def test_SciKit(X_train, X_test, Y_train, Y_test):\n",
        "  #use skitlern library to produce confusion matrix\n",
        "  clf = Perceptron(tol=1e-3, max_iter=5000)\n",
        "  clf.fit(X_train,Y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  matrix = confusion_matrix(Y_test, y_pred)\n",
        "  return matrix\n",
        "\n",
        "def test_Part1():\n",
        "    from sklearn.datasets import load_iris\n",
        "    X_train, y_train = load_iris(return_X_y=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_train[50:],y_train[50:],test_size=0.2)\n",
        "\n",
        "    #Set the labels to +1 and -1\n",
        "    y_train[y_train == 1] = 1\n",
        "    y_train[y_train != 1] = -1\n",
        "    y_test[y_test == 1] = 1\n",
        "    y_test[y_test != 1] = -1\n",
        "\n",
        "    #Pocket algorithm using Numpy\n",
        "    w=fit_perceptron(X_train,y_train)\n",
        "    cM=confMatrix(X_test,y_test,w)\n",
        "\n",
        "    #Pocket algorithm using scikit-learn\n",
        "    sciKit=test_SciKit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    #Print the result\n",
        "    print ('--------------Test Result-------------------')\n",
        "\n",
        "    print(\"Confusion Matrix is from Part 1a is: \",cM)\n",
        "\n",
        "    print(\"Confusion Matrix from Part 1b is:\",sciKit)\n",
        "\n",
        "\n",
        "test_Part1()\n"
      ]
    }
  ]
}